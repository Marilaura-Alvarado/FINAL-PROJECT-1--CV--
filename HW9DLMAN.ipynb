{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c5d7c8-aa87-44a2-8d94-2426e8f2466a",
   "metadata": {},
   "source": [
    "# Deep Learning for Business Applications course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f62655-2e46-4de8-95ed-ceb1f578baba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TOPIC 5: Object detection problem. YOLO training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73aa981-0f41-4a8e-b523-0d3e3d4b761b",
   "metadata": {},
   "source": [
    "### 1. Libraries and configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa90d67-0ed9-4eae-a585-f61fc22c09ee",
   "metadata": {},
   "source": [
    "#### 1.1. Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04217bb0-3144-443f-a9f6-c7f92a7d26b9",
   "metadata": {},
   "source": [
    "[Streamlit](https://streamlit.io/) is a framework that offers a faster way to build and share data applications. It helps you to turn data scripts into shareable web apps in minutes. It is written in pure Python and does not require front‑end experience to work with. Installation is very simple in our environment. Just use terminal or type here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5339f154-3e74-4a0c-b149-a93803240b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepface in /opt/conda/lib/python3.12/site-packages (0.0.96)\n",
      "Requirement already satisfied: requests>=2.27.1 in /opt/conda/lib/python3.12/site-packages (from deepface) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /opt/conda/lib/python3.12/site-packages (from deepface) (2.2.3)\n",
      "Requirement already satisfied: gdown>=3.10.1 in /opt/conda/lib/python3.12/site-packages (from deepface) (5.2.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (4.67.1)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (11.0.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in /opt/conda/lib/python3.12/site-packages (from deepface) (4.12.0.88)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (2.20.0)\n",
      "Requirement already satisfied: keras>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (3.12.0)\n",
      "Requirement already satisfied: Flask>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from deepface) (3.1.2)\n",
      "Requirement already satisfied: flask-cors>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from deepface) (6.0.1)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (1.0.0)\n",
      "Requirement already satisfied: retina-face>=0.0.14 in /opt/conda/lib/python3.12/site-packages (from deepface) (0.0.17)\n",
      "Requirement already satisfied: fire>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (0.7.1)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in /opt/conda/lib/python3.12/site-packages (from deepface) (23.0.0)\n",
      "Requirement already satisfied: lightphe>=0.0.15 in /opt/conda/lib/python3.12/site-packages (from deepface) (0.0.15)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.12/site-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.12/site-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (2.1.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (3.12.1)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface) (0.5.4)\n",
      "Requirement already satisfied: sympy==1.12 in /opt/conda/lib/python3.12/site-packages (from lightphe>=0.0.15->deepface) (1.12)\n",
      "Requirement already satisfied: pytest==7.1.2 in /opt/conda/lib/python3.12/site-packages (from lightphe>=0.0.15->deepface) (7.1.2)\n",
      "Requirement already satisfied: lightecc in /opt/conda/lib/python3.12/site-packages (from lightphe>=0.0.15->deepface) (0.0.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.12/site-packages (from pytest==7.1.2->lightphe>=0.0.15->deepface) (24.2.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.12/site-packages (from pytest==7.1.2->lightphe>=0.0.15->deepface) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.12/site-packages (from pytest==7.1.2->lightphe>=0.0.15->deepface) (1.5.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.12/site-packages (from pytest==7.1.2->lightphe>=0.0.15->deepface) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from pytest==7.1.2->lightphe>=0.0.15->deepface) (2.2.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.12/site-packages (from sympy==1.12->lightphe>=0.0.15->deepface) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
      "Requirement already satisfied: lz4>=4.3.3 in /opt/conda/lib/python3.12/site-packages (from mtcnn>=0.1.0->deepface) (4.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.23.4->deepface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=0.23.4->deepface) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface) (2024.8.30)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (6.33.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (75.6.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (1.68.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface) (2.20.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow>=1.9.0->deepface) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow>=1.9.0->deepface) (0.7.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.12/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f1c110-07bd-4670-9b9e-bfa3d9b52b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.12/site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b47447-2824-46e8-ab59-11a080100303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /opt/conda/lib/python3.12/site-packages (from opencv-python-headless) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908bb1f7-311f-4021-8540-ac1b4da2694a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /opt/conda/lib/python3.12/site-packages (1.51.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (6.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /opt/conda/lib/python3.12/site-packages (from streamlit) (2.2.6)\n",
      "Requirement already satisfied: packaging<26,>=20 in /opt/conda/lib/python3.12/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /opt/conda/lib/python3.12/site-packages (from streamlit) (6.33.1)\n",
      "Requirement already satisfied: pyarrow<22,>=7.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /opt/conda/lib/python3.12/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.12/site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/conda/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /opt/conda/lib/python3.12/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /opt/conda/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (1.15.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34823bc0-94e4-44b9-a0d7-96702d08e99e",
   "metadata": {},
   "source": [
    "#### 1.2. Other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d0f6c8-b2a9-46a6-8055-7524703672c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-cpu==2.16.1 in /opt/conda/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-cpu==2.16.1)\n",
      "  Using cached ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-cpu==2.16.1)\n",
      "  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (1.68.1)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-cpu==2.16.1)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu==2.16.1) (3.12.0)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow-cpu==2.16.1)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu==2.16.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu==2.16.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu==2.16.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu==2.16.1) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow-cpu==2.16.1) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow-cpu==2.16.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow-cpu==2.16.1) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow-cpu==2.16.1) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow-cpu==2.16.1) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow-cpu==2.16.1) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow-cpu==2.16.1) (0.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-cpu==2.16.1) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow-cpu==2.16.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow-cpu==2.16.1) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-cpu==2.16.1) (0.1.2)\n",
      "Using cached ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: protobuf, numpy, tensorboard, ml-dtypes\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.1\n",
      "\u001b[2K    Uninstalling protobuf-6.33.1:\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.1\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: tensorboard0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: tensorboard 2.20.0━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling tensorboard-2.20.0:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.20.0━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: ml-dtypes[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: ml_dtypes 0.5.4\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [ml-dtypes]\n",
      "\u001b[2K    Uninstalling ml_dtypes-0.5.4:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [ml-dtypes]\n",
      "\u001b[2K      Successfully uninstalled ml_dtypes-0.5.40m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [ml-dtypes]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [ml-dtypes]0m [ml-dtypes]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.20.0 requires ml_dtypes<1.0.0,>=0.5.1, but you have ml-dtypes 0.3.2 which is incompatible.\n",
      "tensorflow 2.20.0 requires protobuf>=5.28.0, but you have protobuf 4.25.8 which is incompatible.\n",
      "tensorflow 2.20.0 requires tensorboard~=2.20.0, but you have tensorboard 2.16.2 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ml-dtypes-0.3.2 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.16.2\n",
      "Requirement already satisfied: tf-keras==2.16.0 in /opt/conda/lib/python3.12/site-packages (2.16.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-cpu==2.16.1\n",
    "!pip install tf-keras==2.16.0 --no-dependencies\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d390f276-4198-42cd-aa1c-d3c7a70d0f7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/conda/lib/python3.12/site-packages (8.3.232)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (3.9.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.1.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting numpy>=1.23.0 (from ultralytics)\n",
      "  Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in /opt/conda/lib/python3.12/site-packages (from polars>=0.20.0->ultralytics) (1.35.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (75.6.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, numpy\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.12\n",
      "\u001b[2K    Uninstalling sympy-1.12:\n",
      "\u001b[2K      Successfully uninstalled sympy-1.12━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: numpy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [numpy]32m1/2\u001b[0m [numpy]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.20.0 requires ml_dtypes<1.0.0,>=0.5.1, but you have ml-dtypes 0.3.2 which is incompatible.\n",
      "tensorflow 2.20.0 requires protobuf>=5.28.0, but you have protobuf 4.25.8 which is incompatible.\n",
      "tensorflow 2.20.0 requires tensorboard~=2.20.0, but you have tensorboard 2.16.2 which is incompatible.\n",
      "lightphe 0.0.15 requires sympy==1.12, but you have sympy 1.13.1 which is incompatible.\n",
      "tensorflow-cpu 2.16.1 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.2.6 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.20.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 sympy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651701ae-d261-45e0-bd7e-45906b293e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-cpu in /opt/conda/lib/python3.12/site-packages (2.16.1)\n",
      "Collecting tensorflow-cpu\n",
      "  Using cached tensorflow_cpu-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: tf-keras in /opt/conda/lib/python3.12/site-packages (2.16.0)\n",
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (4.25.8)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (2.5.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (1.68.1)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow-cpu)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow-cpu) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow-cpu)\n",
      "  Using cached ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow-cpu) (3.7)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow-cpu) (11.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow-cpu) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow-cpu) (3.1.3)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /opt/conda/lib/python3.12/site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow-cpu) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow-cpu) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow-cpu) (0.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow-cpu) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow-cpu) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow-cpu) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow-cpu) (0.1.2)\n",
      "Using cached tensorflow_cpu-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259.0 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Installing collected packages: protobuf, ml_dtypes, tensorboard, tensorflow-cpu, tf-keras\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 4.25.8\n",
      "\u001b[2K    Uninstalling protobuf-4.25.8:\n",
      "\u001b[2K      Successfully uninstalled protobuf-4.25.8\n",
      "\u001b[2K  Attempting uninstall: ml_dtypes\n",
      "\u001b[2K    Found existing installation: ml-dtypes 0.3.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [ml_dtypes]\n",
      "\u001b[2K    Uninstalling ml-dtypes-0.3.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [ml_dtypes]\n",
      "\u001b[2K      Successfully uninstalled ml-dtypes-0.3.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [ml_dtypes]\n",
      "\u001b[2K  Attempting uninstall: tensorboard━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [ml_dtypes]\n",
      "\u001b[2K    Found existing installation: tensorboard 2.16.2━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [ml_dtypes]\n",
      "\u001b[2K    Uninstalling tensorboard-2.16.2:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [ml_dtypes]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.16.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [tensorboard]\n",
      "\u001b[2K  Attempting uninstall: tensorflow-cpu\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: tensorflow-cpu 2.16.1━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [tensorboard]\n",
      "\u001b[2K    Uninstalling tensorflow-cpu-2.16.1:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [tensorflow-cpu]\n",
      "\u001b[2K      Successfully uninstalled tensorflow-cpu-2.16.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [tensorflow-cpu]\n",
      "\u001b[2K  Attempting uninstall: tf-keras\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [tensorflow-cpu]\n",
      "\u001b[2K    Found existing installation: tf_keras 2.16.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [tensorflow-cpu]\n",
      "\u001b[2K    Uninstalling tf_keras-2.16.0:━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [tf-keras]u]\n",
      "\u001b[2K      Successfully uninstalled tf_keras-2.16.0\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [tf-keras]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [tf-keras]4/5\u001b[0m [tf-keras]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ml_dtypes-0.5.4 protobuf-6.33.1 tensorboard-2.20.0 tensorflow-cpu-2.20.0 tf-keras-2.20.1\n",
      "Collecting deepface==0.0.95\n",
      "  Using cached deepface-0.0.95-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: requests>=2.27.1 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (2.2.3)\n",
      "Requirement already satisfied: gdown>=3.10.1 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (5.2.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (4.67.1)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (11.0.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (4.12.0.88)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (2.20.0)\n",
      "Requirement already satisfied: keras>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (3.12.0)\n",
      "Requirement already satisfied: Flask>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (3.1.2)\n",
      "Requirement already satisfied: flask-cors>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (6.0.1)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (1.0.0)\n",
      "Requirement already satisfied: retina-face>=0.0.14 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (0.0.17)\n",
      "Requirement already satisfied: fire>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (0.7.1)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in /opt/conda/lib/python3.12/site-packages (from deepface==0.0.95) (23.0.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.12/site-packages (from fire>=0.4.0->deepface==0.0.95) (2.5.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface==0.0.95) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface==0.0.95) (8.1.7)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface==0.0.95) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface==0.0.95) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface==0.0.95) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from Flask>=1.1.2->deepface==0.0.95) (3.1.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.12/site-packages (from gdown>=3.10.1->deepface==0.0.95) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from gdown>=3.10.1->deepface==0.0.95) (3.18.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from gunicorn>=20.1.0->deepface==0.0.95) (24.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface==0.0.95) (2.1.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface==0.0.95) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface==0.0.95) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface==0.0.95) (3.12.1)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface==0.0.95) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.12/site-packages (from keras>=2.2.0->deepface==0.0.95) (0.5.4)\n",
      "Requirement already satisfied: joblib>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from mtcnn>=0.1.0->deepface==0.0.95) (1.4.2)\n",
      "Requirement already satisfied: lz4>=4.3.3 in /opt/conda/lib/python3.12/site-packages (from mtcnn>=0.1.0->deepface==0.0.95) (4.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.23.4->deepface==0.0.95) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.23.4->deepface==0.0.95) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=0.23.4->deepface==0.0.95) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=0.23.4->deepface==0.0.95) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface==0.0.95) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface==0.0.95) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface==0.0.95) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.27.1->deepface==0.0.95) (2024.8.30)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (6.33.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (75.6.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (1.68.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow>=1.9.0->deepface==0.0.95) (2.20.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow>=1.9.0->deepface==0.0.95) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow>=1.9.0->deepface==0.0.95) (0.7.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface==0.0.95) (0.45.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4->gdown>=3.10.1->deepface==0.0.95) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.12/site-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.95) (1.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=2.2.0->deepface==0.0.95) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=2.2.0->deepface==0.0.95) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface==0.0.95) (0.1.2)\n",
      "Using cached deepface-0.0.95-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: deepface\n",
      "  Attempting uninstall: deepface\n",
      "    Found existing installation: deepface 0.0.96\n",
      "    Uninstalling deepface-0.0.96:\n",
      "      Successfully uninstalled deepface-0.0.96\n",
      "Successfully installed deepface-0.0.95\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-cpu tf-keras protobuf\n",
    "!pip install deepface==0.0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac568052-a47b-4a87-a0cc-cb5a30a70ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d80cba5-41d0-4279-b266-1dd16b663878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "068a7356-6b5c-42f1-90e8-f9bfd99ca278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/conda/lib/python3.12/site-packages (8.3.232)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (3.9.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (6.1.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /opt/conda/lib/python3.12/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in /opt/conda/lib/python3.12/site-packages (from polars>=0.20.0->ultralytics) (1.35.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de48cf-d797-4cae-819c-69a586b839ee",
   "metadata": {},
   "source": [
    "#### 1.3. Free space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "463e25f1-3fa9-40c1-b59d-b7ac662dce5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: /home/jovyan/__DATA: Transport endpoint is not connected\n",
      "tmpfs                                      64M     0   64M   0% /dev\n",
      "/dev/vdd                                   12G  8.9G  2.9G  77% /home/jovyan\n",
      "/dev/vda2                                 126G   99G   23G  82% /etc/hosts\n",
      "shm                                        64M     0   64M   0% /dev/shm\n"
     ]
    }
   ],
   "source": [
    "!df -h | grep dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0334c25-dfff-460b-b521-46dd8952b3be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "4 drwxrwsr-x 6 jovyan users 4096 Nov 25 17:31 models--openai--clip-vit-base-patch16\n",
      "total 0\n",
      "total 572344\n",
      "drwxrwsr-x 2 jovyan users      4096 Nov 25 19:17 .\n",
      "drwxrwsr-x 3 jovyan users      4096 Nov 25 19:16 ..\n",
      "-rw-rw-r-- 1 jovyan users   5977392 Dec  7  2021 facial_expression_model_weights.h5\n",
      "-rw-rw-r-- 1 jovyan users 580085408 Nov 25 19:17 vgg_face_weights.h5\n"
     ]
    }
   ],
   "source": [
    "# a cache dir for Huggin Face Hub models\n",
    "!ls -ls ~/.cache/huggingface/hub\n",
    "\n",
    "# a cache dir for PyTorch models\n",
    "!ls -ls ~/.cache/torch/hub/\n",
    "\n",
    "# a cache dir for DeepFace models\n",
    "!ls -la ~/.deepface/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "719e8946-ab4e-411c-a0e9-bbc90d29695a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use `rm -rf` !!! WITH CARE !!!\n",
    "\n",
    "!rm -rf ~/.cache/huggingface/hub\n",
    "!rm -rf ~/.cache/torch/hub/checkpoints\n",
    "!rm -rf ~/.deepface/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d1367-0a9e-4f7c-bb8f-b798ce52d5a6",
   "metadata": {},
   "source": [
    "### 2. How Streamlit works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb7058-ad37-458b-b278-044806419a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Main concepts](https://docs.streamlit.io/library/get-started/main-concepts) require you to create a normal Python script with all necessary elements for your future app and run it with `streamlit run` like `streamlit run your_script.py [-- script args]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e1028-ada6-46e6-85e9-002086c6f6f7",
   "metadata": {},
   "source": [
    "#### 2.1. Python script with app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa5935-7b74-4b17-b664-7113b6d8a469",
   "metadata": {},
   "source": [
    "Streamlit's architecture allows you to write apps the same way you write plain Python scripts. Let's create the sample script with `%%writefile` magic command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3877b6c-2817-4f68-8825-419a8f8a99df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Title of our demo app\n",
    "st.title('Meet the first Streamlit application')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74095332-886b-4cda-8169-a0642cd53aab",
   "metadata": {},
   "source": [
    "#### 2.2. Run application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d23de-7527-44bb-a4ff-a505f7fa7acb",
   "metadata": {},
   "source": [
    "Run application is very easy. Just open a terminal in the folder with your Python script `stapp.py` and type:\n",
    "\n",
    "`streamlit run stapp.py --server.port 20000 --browser.gatherUsageStats False` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951f3ce-28a5-45a9-ac31-e04fbbe002a5",
   "metadata": {},
   "source": [
    "Your Streamlit application will be available with the following URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d15b55-a38a-4888-90d8-b0b26aa99f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit available at: https://jhas01.gsom.spbu.ru/user/st135530/proxy/20000/\n"
     ]
    }
   ],
   "source": [
    "print('Streamlit available at:',\n",
    "      'https://jhas01.gsom.spbu.ru{}proxy/{}/'.format(\n",
    "          os.environ['JUPYTERHUB_SERVICE_PREFIX'], 20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498d5c1-a3fb-4050-bc78-b102d8668511",
   "metadata": {},
   "source": [
    "#### 2.2. Basic examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c63dd-c203-4952-ad67-f29d478a9d43",
   "metadata": {},
   "source": [
    "##### 2.2.1. Nice headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fd66dbb-36fa-433d-829c-9a87340dd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.header('Nice looking header string', divider='rainbow')\n",
    "st.header('_Here is header under the line_ :fire:')\n",
    "\n",
    "st.subheader('Subheader is also here', divider='rainbow')\n",
    "st.subheader(':blue[_We like Streamlit_] :star:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb65cc-d528-48fe-9905-5eab89d38ab8",
   "metadata": {},
   "source": [
    "##### 2.2.2. Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b334000c-10bb-449c-a2f7-9b1bdf6dda5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.header('Just a header', divider='rainbow')\n",
    "st.text('Just a text under the header')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f29cf-9af2-4687-a3fd-8639e809c3f4",
   "metadata": {},
   "source": [
    "##### 2.2.3. Write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d83f88-dad4-477a-a817-23bf578f7fe3",
   "metadata": {},
   "source": [
    "Along with magic commands, `st.write()` is Streamlit's \"Swiss Army knife\". You can pass almost anything to `st.write()`: text, data, Matplotlib figures, charts and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "536fbd00-8d22-4b2e-9adc-e5b72090108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "st.header('Demo of write function', divider='rainbow')\n",
    "st.subheader('Table and plot at one application')\n",
    "\n",
    "st.divider()\n",
    "\n",
    "st.write(\"Here's demo table from the dataframe:\")\n",
    "fruits_data = pd.DataFrame(\n",
    "    {\n",
    "        'fruits': ['apple', 'peach', 'pineapple', 'watermelon'],\n",
    "        'color': ['green', 'orange', 'yellow', 'stripes'],\n",
    "        'weight': [1, 2, 5, 10]\n",
    "    }\n",
    ")\n",
    "st.write(fruits_data)\n",
    "\n",
    "st.divider()\n",
    "\n",
    "st.write(\"Here's demo chart for fruits:\")\n",
    "chart_data = pd.DataFrame(\n",
    "     np.random.randn(20, 4),\n",
    "     columns=['apple', 'peach', 'pineapple', 'watermelon']\n",
    ")\n",
    "st.line_chart(chart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccde3d-f9a5-4ac6-bbdd-faa65c5d82b9",
   "metadata": {},
   "source": [
    "### 3. AI with Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959f5da-09e9-4109-99fa-db3da3ac1407",
   "metadata": {},
   "source": [
    "#### 3.1. Upload pipeline for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e80d0fa-f4d0-4da9-8ce2-0989032f70b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "\n",
    "st.header('Demo of image uploading', divider='rainbow')\n",
    "st.subheader('Uploading file and plot image')\n",
    "st.divider()\n",
    "\n",
    "st.write('#### Upload you image')\n",
    "uploaded_file = st.file_uploader('Select an image file (JPEG format)')\n",
    "if uploaded_file is not None:\n",
    "    file_name = uploaded_file.name\n",
    "    if '.jpg' in file_name:\n",
    "        bytes_data = uploaded_file.read()\n",
    "        img = Image.open(io.BytesIO(bytes_data))\n",
    "        st.divider()\n",
    "        st.image(img, caption='Uploaded image')\n",
    "    else:\n",
    "        st.error('File read error', icon='⚠️')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889616e-5f2e-4ff2-8a92-c9928b93ceb0",
   "metadata": {},
   "source": [
    "#### 3.2. Add some AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a2510ba-77f7-4872-96e4-51765bd3bcf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# use of AI model for image captioning\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    BlipProcessor, \n",
    "    BlipForConditionalGeneration\n",
    ")\n",
    "\n",
    "\n",
    "def img_caption(model, processor, img, text=None):\n",
    "    \"\"\"\n",
    "    Uses BLIP model to caption image.\n",
    "    \n",
    "    \"\"\"\n",
    "    res = None\n",
    "    if text:\n",
    "        # conditional image captioning\n",
    "        inputs = processor(img, text, return_tensors='pt')\n",
    "    else:\n",
    "        # unconditional image captioning\n",
    "        inputs = processor(img, return_tensors='pt')\n",
    "    out = model.generate(**inputs)\n",
    "    res = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return res\n",
    "\n",
    "\n",
    "with st.spinner('Please wait, application is initializing...'):\n",
    "    MODEL_CAP_NAME = 'Salesforce/blip-image-captioning-base'\n",
    "    PROCESSOR_CAP = BlipProcessor.from_pretrained(MODEL_CAP_NAME)\n",
    "    MODEL_CAP = BlipForConditionalGeneration.from_pretrained(MODEL_CAP_NAME)\n",
    "\n",
    "st.header('Demo of image uploading', divider='rainbow')\n",
    "st.subheader('Uploading file and plot image with AI caption')\n",
    "st.divider()\n",
    "\n",
    "st.write('#### Upload you image')\n",
    "uploaded_file = st.file_uploader('Select an image file (JPEG format)')\n",
    "if uploaded_file is not None:\n",
    "    file_name = uploaded_file.name\n",
    "    if '.jpg' in file_name:\n",
    "        # input text for conditional image captioning\n",
    "        text = st.text_input(\n",
    "            'Input text for conditional image captioning (if needed)', \n",
    "            ''\n",
    "        )\n",
    "        with st.spinner('Please wait...'):\n",
    "            bytes_data = uploaded_file.read()\n",
    "            img = Image.open(io.BytesIO(bytes_data))\n",
    "            \n",
    "            # use image caption model for uploaded image\n",
    "            caption = img_caption(\n",
    "                model=MODEL_CAP, \n",
    "                processor=PROCESSOR_CAP, \n",
    "                img=img, \n",
    "                text=text\n",
    "            )\n",
    "            st.divider()\n",
    "            st.image(img, caption=caption)\n",
    "    else:\n",
    "        st.error('File read error', icon='⚠️')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83b0a903-603a-4e72-bb05-f687aee8fef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Use of AI model for image captioning\n",
    "# and object detection at the image\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    BlipProcessor, \n",
    "    BlipForConditionalGeneration\n",
    ")\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "def img_caption(model, processor, img, text=None):\n",
    "    \"\"\"\n",
    "    Uses BLIP model to caption image.\n",
    "    \n",
    "    \"\"\"\n",
    "    res = None\n",
    "    if text:\n",
    "        # conditional image captioning\n",
    "        inputs = processor(img, text, return_tensors='pt')\n",
    "    else:\n",
    "        # unconditional image captioning\n",
    "        inputs = processor(img, return_tensors='pt')\n",
    "    out = model.generate(**inputs)\n",
    "    res = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return res\n",
    "\n",
    "\n",
    "def img_detect(model, img, plot=False):\n",
    "    \"\"\"\n",
    "    Run YOLO inference on an image.\n",
    "    \n",
    "    \"\"\"\n",
    "    result = model(img)[0]\n",
    "    boxes = result.boxes  # boxes object for bounding box outputs\n",
    "    names = model.names\n",
    "    objs = []\n",
    "    for c, p in zip(boxes.cls, boxes.conf):\n",
    "        objs.append({names[int(c)]: p.item()})\n",
    "    img_bgr = result.plot()  # BGR-order numpy array\n",
    "    img_rgb = Image.fromarray(img_bgr[..., ::-1])  # RGB-order PIL image\n",
    "    if plot:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.show()\n",
    "    return objs, img_rgb\n",
    "\n",
    "\n",
    "with st.spinner('Please wait, application is initializing...'):\n",
    "    MODEL_CAP_NAME = 'Salesforce/blip-image-captioning-base'\n",
    "    PROCESSOR_CAP = BlipProcessor.from_pretrained(MODEL_CAP_NAME)\n",
    "    MODEL_CAP = BlipForConditionalGeneration.from_pretrained(MODEL_CAP_NAME)\n",
    "\n",
    "    MODEL_DET_NAME = 'yolov8n.pt'\n",
    "    MODEL_DET = YOLO(MODEL_DET_NAME)\n",
    "\n",
    "st.header('Demo of image uploading', divider='rainbow')\n",
    "st.subheader('Uploading file and plot image with AI caption and YOLO detection')\n",
    "st.divider()\n",
    "\n",
    "st.write('#### Upload you image')\n",
    "uploaded_file = st.file_uploader('Select an image file (JPEG format)')\n",
    "if uploaded_file is not None:\n",
    "    file_name = uploaded_file.name\n",
    "    if '.jpg' in file_name:\n",
    "        # input text for conditional image captioning\n",
    "        text = st.text_input(\n",
    "            'Input text for conditional image captioning (if needed)', \n",
    "            ''\n",
    "        )\n",
    "        with st.spinner('Please wait...'):\n",
    "            bytes_data = uploaded_file.read()\n",
    "            img = Image.open(io.BytesIO(bytes_data))\n",
    "            \n",
    "            # image caption model for uploaded image\n",
    "            caption = img_caption(\n",
    "                model=MODEL_CAP, \n",
    "                processor=PROCESSOR_CAP, \n",
    "                img=img, \n",
    "                text=text\n",
    "            )\n",
    "            st.divider()\n",
    "            st.image(img, caption=caption)\n",
    "            \n",
    "            # object detection model for uploaded image\n",
    "            objs, img_det = img_detect(\n",
    "                model=MODEL_DET, \n",
    "                img=img\n",
    "            )\n",
    "            st.divider()\n",
    "            st.image(img_det, caption='object detection', width=800)\n",
    "            st.divider()\n",
    "            st.caption('Objects dictionary:')\n",
    "            st.write(objs)\n",
    "    else:\n",
    "        st.error('File read error', icon='⚠️')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9692f84-e389-44e2-b325-be19fd9cb045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Use of AI model for image captioning\n",
    "# and object detection at the image\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def zeroshot(classifier, classes, img):\n",
    "    scores = classifier(\n",
    "        img,\n",
    "        candidate_labels=classes\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "\n",
    "with st.spinner('Please wait, application is initializing...'):\n",
    "    MODEL_ZERO_NAME = 'openai/clip-vit-base-patch16'\n",
    "    CLASSIFIER_ZERO = pipeline('zero-shot-image-classification', model=MODEL_ZERO_NAME)\n",
    "    CLASSES = [\n",
    "        'a photo of nature',\n",
    "        'a photo of cat',\n",
    "        'a photo of a party',\n",
    "        'a photo of a food'\n",
    "    ]\n",
    "\n",
    "st.header('Demo of image uploading', divider='rainbow')\n",
    "st.subheader('Uploading file and classifying it with zero-shot')\n",
    "st.divider()\n",
    "\n",
    "st.write('#### Upload you image')\n",
    "uploaded_file = st.file_uploader('Select an image file (JPEG format)')\n",
    "if uploaded_file is not None:\n",
    "    file_name = uploaded_file.name\n",
    "    if '.jpg' in file_name:\n",
    "        with st.spinner('Please wait...'):\n",
    "            bytes_data = uploaded_file.read()\n",
    "            img = Image.open(io.BytesIO(bytes_data))\n",
    "            \n",
    "            # classifying image with zero-shot modele\n",
    "            scores = zeroshot(\n",
    "                classifier=CLASSIFIER_ZERO, \n",
    "                classes=CLASSES, \n",
    "                img=img\n",
    "            )\n",
    "            st.divider()\n",
    "            st.image(img, caption='zero-shot classification')\n",
    "            \n",
    "            # plot a diagram ith scores and scores output\n",
    "            st.divider()\n",
    "            df = pd.DataFrame(scores)\n",
    "            df = df.set_index('label')\n",
    "            st.bar_chart(df)\n",
    "            st.divider()\n",
    "            st.caption('Scores dictionary:')\n",
    "            st.write(scores)\n",
    "    else:\n",
    "        st.error('File read error', icon='⚠️')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5a314-6294-4005-8957-b8de29984ece",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.3. Add some OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78889b0e-e7a7-47a2-bc7b-450217f431f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Use of OCR model for text extracting \n",
    "# from image or PDF file\n",
    "\n",
    "import io\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_bytes\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pdf2img(pdf_bytes):\n",
    "    \"\"\"\n",
    "    Turns pdf file to set of jpeg images.\n",
    "\n",
    "    \"\"\"\n",
    "    images = convert_from_bytes(pdf_bytes.read())\n",
    "    return images\n",
    "\n",
    "\n",
    "def ocr_text(img, lang='eng'):\n",
    "    \"\"\"\n",
    "    Takes the text from image.\n",
    "    \n",
    "    :lang: language is `eng` by default,\n",
    "           use `eng+rus` for two languages in document\n",
    "\n",
    "    \"\"\"\n",
    "    text = str(pytesseract.image_to_string(\n",
    "        img,\n",
    "        lang=lang\n",
    "    ))\n",
    "    return text\n",
    "\n",
    "\n",
    "def ocr_text_dir(img_dir, lang='eng'):\n",
    "    \"\"\"\n",
    "    Takes the text from images in a folder.\n",
    "\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for img_name in tqdm(sorted(os.listdir(img_dir))):\n",
    "        if '.jpg' in img_name:\n",
    "            img = Image.open(f'{IMG_PATH}/{img_name}')\n",
    "            text_tmp = ocr_text(img, lang=lang)\n",
    "            text = ' '.join([text, text_tmp])\n",
    "    return text\n",
    "\n",
    "\n",
    "st.header('Demo of image uploading', divider='rainbow')\n",
    "st.subheader('Uploading file and extracting text from it')\n",
    "st.divider()\n",
    "\n",
    "st.write('#### Upload you file or image')\n",
    "uploaded_file = st.file_uploader('Select a file (JPEG or PDF)')\n",
    "if uploaded_file is not None:\n",
    "    file_name = uploaded_file.name\n",
    "    lang = st.selectbox(\n",
    "            'Select language to extract ',\n",
    "            ('eng', 'rus', 'eng+rus')\n",
    "        )\n",
    "    if '.jpg' in file_name:\n",
    "        with st.spinner('Please wait...'):\n",
    "            bytes_data = uploaded_file.read()\n",
    "            img = Image.open(io.BytesIO(bytes_data))\n",
    "            \n",
    "            # image caption model for uploaded image\n",
    "            text = ocr_text(img, lang=lang)\n",
    "            st.divider()\n",
    "            st.write('#### Text extracted')\n",
    "            st.write(text)\n",
    "    elif '.pdf' in file_name:\n",
    "        with st.spinner('Please wait...'):\n",
    "            imgs = pdf2img(uploaded_file)\n",
    "            text = ''\n",
    "            for img in imgs:\n",
    "                text_tmp = ocr_text(img, lang=lang)\n",
    "                text = ' '.join([text, text_tmp])\n",
    "            st.divider()\n",
    "            st.write('#### Text extracted')\n",
    "            st.write(text)\n",
    "    else:\n",
    "        st.error('File read error', icon='⚠️')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca128d06-5fe3-48ab-a6b7-6b6bea0ac856",
   "metadata": {},
   "source": [
    "### 3.4. Add some faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e1f4c66-d4a2-403f-a7e6-b704967eb5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Using cached sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in /opt/conda/lib/python3.12/site-packages (from sumy) (0.6.2)\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Using cached breadability-0.1.20-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.7.0 in /opt/conda/lib/python3.12/site-packages (from sumy) (2.32.3)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nltk>=3.0.2 in /opt/conda/lib/python3.12/site-packages (from sumy) (3.9.1)\n",
      "Collecting chardet (from breadability>=0.1.20->sumy)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: lxml>=2.0 in /opt/conda/lib/python3.12/site-packages (from breadability>=0.1.20->sumy) (5.3.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2024.8.30)\n",
      "Using cached sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: pycountry, chardet, breadability, sumy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [sumy][32m3/4\u001b[0m [sumy]et]\n",
      "\u001b[1A\u001b[2KSuccessfully installed breadability-0.1.20 chardet-5.2.0 pycountry-24.6.1 sumy-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "900be527-4853-46a3-86e3-13c96e64ec7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Use of DeepFace framework\n",
    "# for faces detection and recognotion\n",
    "\n",
    "import io\n",
    "import cv2\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def zeroshot(classifier, classes, img):\n",
    "    scores = classifier(\n",
    "        img,\n",
    "        candidate_labels=classes\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "\n",
    "with st.spinner('Please wait, application is initializing...'):\n",
    "    MODEL_ZERO_NAME = 'openai/clip-vit-base-patch16'\n",
    "    CLASSIFIER_ZERO = pipeline('zero-shot-image-classification', model=MODEL_ZERO_NAME)\n",
    "    CLASSES = [\n",
    "        'a photo of nature',\n",
    "        'a photo of cat',\n",
    "        'a photo of a party',\n",
    "        'a photo of a food'\n",
    "    ]\n",
    "    DEEPFACE_MODELS = [\n",
    "        'VGG-Face',\n",
    "        'Facenet',\n",
    "        'Facenet512',\n",
    "        'OpenFace',\n",
    "        'DeepFace',\n",
    "        'DeepID',\n",
    "        'ArcFace',\n",
    "        'Dlib',\n",
    "        'SFace',\n",
    "        'GhostFaceNet'\n",
    "    ]\n",
    "    DB_PATH = '/home/jovyan/dlba/topic_09/app/data/db'\n",
    "\n",
    "st.header('Demo of image uploading', divider='rainbow')\n",
    "st.subheader('Uploading file and classifying it with zero-shot and face recognition')\n",
    "st.divider()\n",
    "\n",
    "st.write('#### Upload you image')\n",
    "uploaded_file = st.file_uploader('Select an image file (JPEG format)')\n",
    "if uploaded_file is not None:\n",
    "    file_name = uploaded_file.name\n",
    "    if '.jpg' in file_name:\n",
    "        with st.spinner('Please wait...'):\n",
    "            bytes_data = uploaded_file.read()\n",
    "            img = Image.open(io.BytesIO(bytes_data))\n",
    "            \n",
    "            # classifying image with zero-shot modele\n",
    "            scores = zeroshot(\n",
    "                classifier=CLASSIFIER_ZERO, \n",
    "                classes=CLASSES, \n",
    "                img=img\n",
    "            )\n",
    "            st.divider()\n",
    "            st.image(img, caption='zero-shot classification')\n",
    "            \n",
    "            # plot a diagram ith scores and scores output\n",
    "            st.divider()\n",
    "            df = pd.DataFrame(scores)\n",
    "            df = df.set_index('label')\n",
    "            st.bar_chart(df)\n",
    "            st.divider()\n",
    "            st.caption('Scores dictionary:')\n",
    "            st.write(scores)\n",
    "            \n",
    "            # faces detection and recognition\n",
    "            results = DeepFace.find(\n",
    "                img_path=np.array(img),  # face to find\n",
    "                db_path=f'{DB_PATH}',  # path to directory with faces\n",
    "                model_name=DEEPFACE_MODELS[0],\n",
    "                enforce_detection=False\n",
    "            )\n",
    "            st.divider()\n",
    "            st.caption('Faces recognition:')\n",
    "            found = []\n",
    "            for result in results:\n",
    "                if len(result):\n",
    "                    name = result.identity.values\n",
    "                    if name:\n",
    "                        found.append(\n",
    "                            name[0].replace(f'{DB_PATH}/', '').replace('.jpg', '')\n",
    "                        )\n",
    "            if found:\n",
    "                st.write(f'Found: {\" ,\".join(found)}')\n",
    "            else:\n",
    "                st.write('No known faces found')\n",
    "    else:\n",
    "        st.error('File read error', icon='⚠️')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45be59-3147-4116-b8f0-9ab4555ea8a7",
   "metadata": {},
   "source": [
    "## 4. Move to developing app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd486b-d1a3-4f75-a181-372e0ee2e9b7",
   "metadata": {},
   "source": [
    "Let's get out Jupyter notebooks to a hardcore development process..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119322e9-8ec7-46c3-9352-1a803f1eadb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='red'>HOME ASSIGNMENT (Final project)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb81d902-323d-4dc5-997e-420d234b2e04",
   "metadata": {},
   "source": [
    "Your final project tasks are:\n",
    "1. Enlarge number of categories for uploaded images classification\n",
    "2. Change YOLO detection to segmentation model (use new version of YOLO, version 11 is released)\n",
    "3. Apply emotion detector model and add emotions for your friends faces recognition pipeline\n",
    "4. Implement application's page for OCR with Tesseract library\n",
    "5. Add text summarization option for text extracted in OCR page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495287f6-5d38-4ecf-9c81-2afe33fa639b",
   "metadata": {},
   "source": [
    "<font color='red'>Use application code snippets for the Final project, not the notebooks!</font> To run application (1) move to `app` directory (2) use the following command from the terminal:\n",
    "\n",
    "`streamlit run app/Main_page.py --server.port 20000 --browser.gatherUsageStats False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "021e2ac1-a72d-460f-93bf-bf599edffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note for the teacher: I tried to make the page to look more beautiful and not make it that simple, as currently I am learning how to do the frontend, so I used this task to practice, that is why I added also emojies and other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ad7ff14-5689-4a37-9330-ae93cb96d4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import pipeline\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import pytesseract\n",
    "\n",
    "# ---- Page config must be BEFORE any other st.* call ----\n",
    "st.set_page_config(page_title=\"CV Final Project\", layout=\"wide\")\n",
    "\n",
    "# ---- Custom blue style ----\n",
    "def add_custom_css():\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "        .stApp {\n",
    "            background: radial-gradient(circle at top left, #1d4ed8 0, #020617 45%, #020617 100%);\n",
    "            color: #e5e7eb;\n",
    "        }\n",
    "        .stTabs [role=\"tablist\"] button {\n",
    "            background-color: rgba(15, 23, 42, 0.5);\n",
    "            color: #e5e7eb;\n",
    "            border-radius: 999px;\n",
    "            padding: 0.35rem 1.1rem;\n",
    "            margin-right: 0.35rem;\n",
    "            border: 1px solid rgba(59, 130, 246, 0.6);\n",
    "        }\n",
    "        .stTabs [role=\"tablist\"] button[data-selected=\"true\"] {\n",
    "            background-color: #2563eb;\n",
    "            color: #f9fafb;\n",
    "            border-color: #60a5fa;\n",
    "        }\n",
    "        .stButton > button {\n",
    "            border-radius: 999px;\n",
    "            border: 1px solid #60a5fa;\n",
    "            background: linear-gradient(90deg, #2563eb, #1d4ed8);\n",
    "            color: #f9fafb;\n",
    "            padding: 0.35rem 1.2rem;\n",
    "        }\n",
    "        .stButton > button:hover {\n",
    "            border-color: #93c5fd;\n",
    "            filter: brightness(1.05);\n",
    "        }\n",
    "        .stFileUploader label {\n",
    "            color: #e5e7eb !important;\n",
    "        }\n",
    "        .blue-card {\n",
    "            padding: 1rem 1.25rem;\n",
    "            margin-bottom: 1rem;\n",
    "            border-radius: 1rem;\n",
    "            background: rgba(15, 23, 42, 0.85);\n",
    "            border: 1px solid rgba(59, 130, 246, 0.6);\n",
    "        }\n",
    "        .blue-title {\n",
    "            font-size: 1.3rem;\n",
    "            font-weight: 600;\n",
    "            color: #e5e7eb;\n",
    "            margin-bottom: 0.25rem;\n",
    "        }\n",
    "        .blue-subtitle {\n",
    "            font-size: 0.9rem;\n",
    "            color: #9ca3af;\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True,\n",
    "    )\n",
    "\n",
    "def zeroshot(classifier, classes, img):\n",
    "    \"\"\"Zero-shot image classification.\"\"\"\n",
    "    scores = classifier(\n",
    "        img,\n",
    "        candidate_labels=classes,\n",
    "        hypothesis_template=\"This is {}.\",\n",
    "    )\n",
    "    scores = sorted(scores, key=lambda x: x[\"score\"], reverse=True)\n",
    "    return scores\n",
    "\n",
    "def run_segmentation(model, img):\n",
    "    \"\"\"YOLOv11 segmentation on a PIL image. Returns segmented PIL image.\"\"\"\n",
    "    img_np = np.array(img)\n",
    "    results = model(img_np)[0]\n",
    "    seg_bgr = results.plot()  # BGR array with masks\n",
    "    seg_rgb = cv2.cvtColor(seg_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(seg_rgb)\n",
    "\n",
    "def extract_ocr_text(img, lang=\"eng\"):\n",
    "    \"\"\"Run Tesseract OCR on a PIL image (English only).\"\"\"\n",
    "    gray = img.convert(\"L\")\n",
    "    w, h = gray.size\n",
    "    if max(w, h) < 900:\n",
    "        gray = gray.resize((w * 2, h * 2))\n",
    "    text = pytesseract.image_to_string(gray, lang=lang)\n",
    "    return text\n",
    "\n",
    "def summarize_text(text, max_sentences=2):\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    sentences = [s for s in sentences if s]\n",
    "    return \" \".join(sentences[:max_sentences])\n",
    "\n",
    "def detect_emotions(img):\n",
    "    \"\"\"\n",
    "    Safe DeepFace emotion detection wrapper.\n",
    "    Returns None if model cannot be loaded (weights missing / no internet).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = DeepFace.analyze(\n",
    "            img_path=np.array(img),\n",
    "            actions=[\"emotion\"],\n",
    "            enforce_detection=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Emotion detection error:\", e)\n",
    "        return None\n",
    "\n",
    "    emotions = []\n",
    "    if isinstance(result, list):\n",
    "        for r in result:\n",
    "            emotions.append(r.get(\"dominant_emotion\", \"unknown\"))\n",
    "    else:\n",
    "        emotions.append(result.get(\"dominant_emotion\", \"unknown\"))\n",
    "\n",
    "    return emotions\n",
    "\n",
    "def recognize_faces(img, db_path, model_name):\n",
    "    \"\"\"\n",
    "    DeepFace face recognition against DB_PATH.\n",
    "    Returns list of recognized names, only if distance is small enough.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = DeepFace.find(\n",
    "            img_path=np.array(img),\n",
    "            db_path=db_path,\n",
    "            model_name=model_name,\n",
    "            distance_metric=\"cosine\",\n",
    "            threshold=1.0,\n",
    "            enforce_detection=False,\n",
    "        )\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "    DISTANCE_THRESHOLD = 0.80\n",
    "    found = set()\n",
    "    dfs = results if isinstance(results, list) else [results]\n",
    "\n",
    "    for df in dfs:\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "\n",
    "        df_sorted = df.sort_values(\"distance\", ascending=True)\n",
    "        best = df_sorted.iloc[0]\n",
    "        best_identity = best[\"identity\"]\n",
    "        best_distance = float(best[\"distance\"])\n",
    "\n",
    "        print(\"Best match:\", best_identity, \"distance:\", best_distance)\n",
    "\n",
    "        if best_distance > DISTANCE_THRESHOLD:\n",
    "            return []\n",
    "\n",
    "        name = os.path.basename(best_identity).rsplit(\".\", 1)[0]\n",
    "        found.add(name)\n",
    "\n",
    "    return list(found)\n",
    "\n",
    "# ---- Add CSS before drawing UI ----\n",
    "add_custom_css()\n",
    "\n",
    "# ---- Models & config (spinner) ----\n",
    "with st.spinner(\"Initializing models, this may take a bit...\"):\n",
    "    MODEL_ZERO_NAME = \"openai/clip-vit-base-patch16\"\n",
    "    CLASSIFIER_ZERO = pipeline(\n",
    "        \"zero-shot-image-classification\",\n",
    "        model=MODEL_ZERO_NAME,\n",
    "    )\n",
    "\n",
    "    CLASSES = [\n",
    "        \"a photo of nature\",\n",
    "        \"a photo of a cat\",\n",
    "        \"a photo of a party\",\n",
    "        \"a photo of food\",\n",
    "        \"a city street\",\n",
    "        \"a building interior\",\n",
    "        \"a document with text\",\n",
    "        \"a person's photo\",\n",
    "        \"a landscape with water\",\n",
    "    ]\n",
    "\n",
    "    DEEPFACE_MODEL_NAME = \"VGG-Face\"\n",
    "    BASE_DIR = os.path.dirname(__file__) if \"__file__\" in globals() else \".\"\n",
    "    DB_PATH = os.path.join(BASE_DIR, \"app\", \"data\", \"db\")\n",
    "    os.makedirs(DB_PATH, exist_ok=True)\n",
    "\n",
    "    SEG_MODEL_NAME = \"yolo11n-seg.pt\"\n",
    "    SEG_MODEL = YOLO(SEG_MODEL_NAME)\n",
    "\n",
    "# ---- Top section ----\n",
    "st.title(\"💙 Computer Vision Final Project\")\n",
    "st.caption(\n",
    "    \"Zero-shot classification • Face recognition with emotions • YOLOv11 segmentation • OCR + summarization\"\n",
    ")\n",
    "\n",
    "tab1, tab2, tab3 = st.tabs(\n",
    "    [\n",
    "        \"1. Classification & Faces\",\n",
    "        \"2. YOLOv11 Segmentation\",\n",
    "        \"3. OCR + Text Summarization\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---------- TAB 1 ----------\n",
    "with tab1:\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div class=\"blue-card\">\n",
    "            <div class=\"blue-title\">Image classification + friends recognition + emotions</div>\n",
    "            <div class=\"blue-subtitle\">\n",
    "                Upload a photo and the app will classify it, try to find your friends in the database,\n",
    "                and estimate the dominant emotions for detected faces.\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True,\n",
    "    )\n",
    "\n",
    "    uploaded_file = st.file_uploader(\n",
    "        \"Upload an image (JPEG/PNG)\",\n",
    "        type=[\"jpg\", \"jpeg\", \"png\"],\n",
    "        key=\"tab1_uploader\",\n",
    "    )\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        file_name = uploaded_file.name\n",
    "        if any(file_name.lower().endswith(ext) for ext in [\".jpg\", \".jpeg\", \".png\"]):\n",
    "            with st.spinner(\"Processing image...\"):\n",
    "                bytes_data = uploaded_file.read()\n",
    "                img = Image.open(io.BytesIO(bytes_data)).convert(\"RGB\")\n",
    "\n",
    "                scores = zeroshot(\n",
    "                    classifier=CLASSIFIER_ZERO,\n",
    "                    classes=CLASSES,\n",
    "                    img=img,\n",
    "                )\n",
    "\n",
    "                # ---- write to history.log (Tab 1) ----\n",
    "                LOG_PATH = \"history.log\"\n",
    "                msg = \"{} - file '{}' processed in Tab 1 (classification/faces)\\n\".format(\n",
    "                    datetime.datetime.now(),\n",
    "                    file_name,\n",
    "                )\n",
    "                with open(LOG_PATH, \"a\") as f:\n",
    "                    f.write(msg)\n",
    "\n",
    "            st.subheader(\"🎯 Zero-shot classification\")\n",
    "            st.image(img, caption=\"Uploaded image\", use_container_width=True)\n",
    "\n",
    "            df_scores = pd.DataFrame(scores).set_index(\"label\")\n",
    "            st.bar_chart(df_scores[\"score\"])\n",
    "            st.caption(\"Raw scores:\")\n",
    "            st.write(scores)\n",
    "\n",
    "            st.caption(f\"DB_PATH used by app: {DB_PATH}\")\n",
    "            st.caption(f\"Files in DB: {os.listdir(DB_PATH)}\")\n",
    "\n",
    "            st.subheader(\"👥 Face recognition (DeepFace)\")\n",
    "            recognized = recognize_faces(\n",
    "                img=img,\n",
    "                db_path=DB_PATH,\n",
    "                model_name=DEEPFACE_MODEL_NAME,\n",
    "            )\n",
    "            if recognized:\n",
    "                st.success(\"Recognized: \" + \", \".join(recognized))\n",
    "            else:\n",
    "                st.info(\"No known faces found.\")\n",
    "\n",
    "            st.subheader(\"😊 Emotion detection\")\n",
    "            emotions = detect_emotions(img)\n",
    "\n",
    "            if emotions is None:\n",
    "                st.warning(\n",
    "                    \"Emotion detection is currently unavailable because the DeepFace \"\n",
    "                    \"emotion model could not be downloaded in this environment.\"\n",
    "                )\n",
    "            elif emotions:\n",
    "                st.write(\"Detected emotions:\", \", \".join(emotions))\n",
    "            else:\n",
    "                st.write(\"No emotions detected.\")\n",
    "\n",
    "# --- TAB 2 ---\n",
    "with tab2:\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div class=\"blue-card\">\n",
    "            <div class=\"blue-title\">YOLOv11 segmentation</div>\n",
    "            <div class=\"blue-subtitle\">\n",
    "                The model highlights objects with masks and bounding boxes using YOLOv11 segmentation.\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True,\n",
    "    )\n",
    "\n",
    "    uploaded_seg = st.file_uploader(\n",
    "        \"Upload an image (JPEG/PNG) for segmentation\",\n",
    "        type=[\"jpg\", \"jpeg\", \"png\"],\n",
    "        key=\"tab2_uploader\",\n",
    "    )\n",
    "\n",
    "    if uploaded_seg is not None:\n",
    "        file_name = uploaded_seg.name\n",
    "        if any(file_name.lower().endswith(ext) for ext in [\".jpg\", \".jpeg\", \".png\"]):\n",
    "            with st.spinner(\"Running YOLOv11 segmentation...\"):\n",
    "                bytes_data = uploaded_seg.read()\n",
    "                img = Image.open(io.BytesIO(bytes_data)).convert(\"RGB\")\n",
    "                seg_img = run_segmentation(SEG_MODEL, img)\n",
    "\n",
    "              \n",
    "                LOG_PATH = \"history.log\"\n",
    "                msg = \"{} - file '{}' processed in Tab 2 (segmentation)\\n\".format(\n",
    "                    datetime.datetime.now(),\n",
    "                    file_name,\n",
    "                )\n",
    "                with open(LOG_PATH, \"a\") as f:\n",
    "                    f.write(msg)\n",
    "\n",
    "            col1, col2 = st.columns(2)\n",
    "            with col1:\n",
    "                st.subheader(\"Original image\")\n",
    "                st.image(img, use_container_width=True)\n",
    "            with col2:\n",
    "                st.subheader(\"Segmented image\")\n",
    "                st.image(seg_img, caption=\"YOLOv11 segmentation result\", use_container_width=True)\n",
    "        else:\n",
    "            st.error(\n",
    "                \"File read error: please upload .jpg, .jpeg or .png\",\n",
    "                icon=\"⚠️\",\n",
    "            )\n",
    "\n",
    "# --- TAB 3 start here\n",
    "with tab3:\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <div class=\"blue-card\">\n",
    "            <div class=\"blue-title\">OCR with Tesseract + Text summarization</div>\n",
    "            <div class=\"blue-subtitle\">\n",
    "                Extract text from an image using Tesseract, then summarize it with a transformer model.\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True,\n",
    "    )\n",
    "\n",
    "    uploaded_ocr = st.file_uploader(\n",
    "        \"Upload an image (JPEG/PNG) with text\",\n",
    "        type=[\"jpg\", \"jpeg\", \"png\"],\n",
    "        key=\"tab3_uploader\",\n",
    "    )\n",
    "\n",
    "    if uploaded_ocr is not None:\n",
    "        file_name = uploaded_ocr.name\n",
    "        if any(file_name.lower().endswith(ext) for ext in [\".jpg\", \".jpeg\", \".png\"]):\n",
    "            with st.spinner(\"Running OCR...\"):\n",
    "                bytes_data = uploaded_ocr.read()\n",
    "                img = Image.open(io.BytesIO(bytes_data)).convert(\"RGB\")\n",
    "                text = extract_ocr_text(img)\n",
    "\n",
    "                \n",
    "                LOG_PATH = \"history.log\"\n",
    "                msg = \"{} - file '{}' processed in Tab 3 (OCR)\\n\".format(\n",
    "                    datetime.datetime.now(),\n",
    "                    file_name,\n",
    "                )\n",
    "                with open(LOG_PATH, \"a\") as f:\n",
    "                    f.write(msg)\n",
    "\n",
    "            st.subheader(\"🖼️ Image\")\n",
    "            st.image(img, use_container_width=True)\n",
    "\n",
    "            st.subheader(\"📝 Extracted text\")\n",
    "            text = st.text_area(\n",
    "                \"OCR result (you can edit before summarizing):\",\n",
    "                value=text,\n",
    "                height=200,\n",
    "            )\n",
    "\n",
    "            if st.button(\"Summarize text\"):\n",
    "                with st.spinner(\"Summarizing...\"):\n",
    "                    summary = summarize_text(text)\n",
    "                st.subheader(\"📌 Summary\")\n",
    "                st.write(summary)\n",
    "        else:\n",
    "            st.error(\n",
    "                \"File read error: please upload .jpg, .jpeg or .png\",\n",
    "                icon=\"⚠️\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801542a-3ad8-4e78-bcf9-88fe2da55e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c41e9-bcee-4a8f-a4e7-00f571559ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
